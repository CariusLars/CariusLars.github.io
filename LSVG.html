<!DOCTYPE html>
<!--[if IE 8 ]><html class="no-js oldie ie8" lang="en"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html class="no-js" lang="en"> <!--<![endif]-->
<head>

   <!--- basic page needs
   ================================================== -->
   <meta charset="utf-8">
	<title>LSVG - Latent Space Video Generation</title>
	<meta name="description" content="">  
	<meta name="author" content="">

   <!-- mobile specific metas
   ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

 	<!-- CSS
   ================================================== -->
   <link rel="stylesheet" href="css/base.css">
   <link rel="stylesheet" href="css/vendor.css">  
   <link rel="stylesheet" href="css/main.css">
        

   <!-- script
   ================================================== -->
	<script src="js/modernizr.js"></script>
	<script src="js/pace.min.js"></script>

   <!-- favicons
	================================================== -->
	<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	<link rel="icon" href="favicon.ico" type="image/x-icon">

</head>

<body id="top">

	<!-- header 
   ================================================== -->
   <header class="short-header">   

   	<div class="gradient-block"></div>	

   	<div class="row header-content">

   		<div class="logo">
	         <a href="index.html">Author</a>
	      </div>

	   	<nav id="main-nav-wrap">
				<ul class="main-navigation sf-menu">
					<li><a href="index.html" title="">Home</a></li>									
					<li class="has-children">
						Categories
						<ul class="sub-menu">
			            <li><a href="category_machinelearning.html">Machine Learning</a></li><li><a href="category_ar.html">Augmented Reality</a></li><li><a href="category_microcontroller.html">Microcontroller</a></li>
			            <li><a href="category_hardware.html">Hardware</a></li>
			         </ul>
					</li>
					<li class="has-children current">
						Blog
						<ul class="sub-menu">
			            <!-- <li><a href="single-video.html">Video Post</a></li>
			            <li><a href="single-audio.html">Audio Post</a></li>
			            <li><a href="single-gallery.html">Gallery Post</a></li>
			            <li><a href="single-standard.html">Standard Post</a></li>-->
						<li><a href="led_sign.html">LED Sign</a></li><li><a href="ar_order.html">Augmented Reality Beer Orders</a></li><li><a href="led_sign.html">LED Sign</a></li>
						<li><a href="futuregan_depth.html">RGB-D Video GAN</a></li>
						<li><a href="LSVG.html">Latent Space Video Generation</a></li><li><a href="coopRL.html">Cooperative Reinforcement Learning</a></li>
			         </ul>
					</li>
					<!--<li><a href="style-guide.html" title="">Styles</a></li>-->
					<li><a href="about.html" title="">About Me</a></li>
					<li><a href="contact.html" title="">Contact</a></li>										
				</ul>
			</nav> <!-- end main-nav-wrap -->

			<!--<div class="search-wrap">

				<form role="search" method="get" class="search-form" action="#">
					<label>
						<span class="hide-content">Search for:</span>
						<input type="search" class="search-field" placeholder="Type Your Keywords" value="" name="s" title="Search for:" autocomplete="off">
					</label>
					<input type="submit" class="search-submit" value="Search">
				</form>

				<a href="#" id="close-search" class="close-btn">Close</a>

			</div>--> <!-- end search wrap -->

			<div class="triggers">
				<!--<a class="search-trigger" href="#"><i class="fa fa-search"></i></a>-->
				<a class="menu-toggle" href="#"><span>Menu</span></a>
			</div> <!-- end triggers -->
   		
   	</div>     		
   	
   </header> <!-- end header -->
   

   <!-- content
   ================================================== -->
   <section id="content-wrap" class="blog-single">
   	<div class="row">
   		<div class="col-twelve">

   			<article class="format-standard">  

   				<div class="content-media">
						<div class="post-thumb">
							<img src="images/LSVG/mnist.png" style="max-width:100%;" >
							<p style="text-align:right;font-size:50%;">Image taken from	<a href="https://hackernoon.com/latent-space-visualization-deep-learning-bits-2-bd09a46920df">this blog</a></p>

						</div>  
					</div>

					<img class="primary-content">

						<h1 class="page-title">Leveraging Smooth Latent Spaces for Video Generation</h1>

						<ul class="entry-meta">
							<li class="date">February 04, 2020</li>
							<li class="cat"><a href="category_machinelearning.html">Machine Learning</a></li>
						</ul>						

						<p class="lead">There's been a rise in papers that blend images into one another by interpolating in the latent space
						of a previously trained network. We developed a pipeline that uses the same principle to generate short video clips from a set of input images</p>

						<p>If you are interested in Generative Adversarial Networks (GANs) or Autoencoders, you've probably come across pictures like this one:</p>
												<figure>
							<img src="images/LSVG/interpolation.jpeg" style="width:100%">
							<figcaption>Image taken from <a href="https://arxiv.org/pdf/1707.05776.pdf">this paper</a></figcaption>
						</figure>
						<p>What you see here are images generated by interpolating in latent space. On a very high level, imagine the left- and rightmost pictures
						as your originals, then all images in-between are just a blend of the young women and the middle-aged man. To better understand how this
						blending actually works, let's first have a look into what a latent space is.</p>
						<figure>
							<img src="images/LSVG/GAN_concept.svg" style="width:100%">
						</figure>
						<p>The above sketch shows the abstract structure of a GAN. Let's have a look a the elements: First, we have our latent vector. You can just picture it
						as a vector of random real numbers for now. The Generator is a Neural Network that turns those random numbers into an image that we call Fake Image
						for now. A second Neural Network, the Critic, alternately receives a generated, fake image and a real image from our dataset and outputs a score trying
						to determine whether the current image is real or fake.<br>
						Essentially, the Generator and the Critic compete while a GAN is trained. The Critic continuously learns to tell real images apart from generated images,
						the Generator tries to fool the Critic and thus produces more and more realistic images.<br>
						What's the deal with the latent vector though? We don't want our generator to always produce the same image. In a perfect world
						without any training issues and without that nasty phenomenon we call Mode Collapse, every combination of numbers in our latent vector
						produces a different image when fed through the generator. We can then sample a random latent vector whenever we want a new image. </p>

						<p>Let's get back to our interpolated faces from the start. Researchers have gotten pretty good at achieving smooth latent spaces. More abstractly,
						this means that almost every latent vector produces a different, but realistic image when fed through the trained generator network. They also realized
						that different entries in the latent vector influence different aspects of the image. Take faces as an example: If your latent vector has 100 entries (so-called dimensions of latent space),
						it's likely that one of them exclusively influences hair color. If you were to generate faces from this vector and only change your hair-color dimension,
						the generated faces will be almost identical, but the hair colors would differ. </p>
						<figure>
							<img src="images/LSVG/ConceptInterpolation.svg" style="width:50%">
						</figure>
						<p>The same idea is used for interpolating between faces. First, we generate two random latent vectors, send them through our generator and
						out come two different faces: The young lady and the middle-aged man. Now picture those latent vectors as points in latent space. The figure
						above shows linear interpolation in 3.dimensional space: We have two points, draw a line between them and generate new points at equidistant
						steps of the line. Our latent space has a lot more dimensions, but the principle stays the same: We calculate the formula for a line between
						the latent vector of the young women and the one of the middle-aged man and draw new latent vectors along the line. As we learned before, entries
						in the latent vectors stand for features of the faces, so all we need to do now is send our new samples through the generator network and voil&agrave;,
						we get faces with a gradual blend between the face characteristics of our young lady and our man.</p>

						<p>Now that we know about the basics of latent vectors and GANs, we can finally get to the new stuff! Generating novel, realistic images is very
						impressive, but "dreaming up" never-before-seen videos is, kind of, the holy grail of using GANs. The problem with videos is that not only the individual
						frames have to look realistic, but you also need so-called temporal consistency, meaning that the concatenation of all your predicted frames has to look
						like a realistic video, especially with realistic movement of objects. <br>
						Many approaches exist for the challenge, but the countless interpolation images inspired us to try something new: What if we can train a GAN
						to develop a latent space so smooth that we can simply interpolate between two still images and generate so many frames in-between that we can build
						a whole video from it? We don't want random videos though, do we? We also want to influence what our video is about. Long story short, this is what we
						came up with:</p>
						<figure>
							<img src="images/LSVG/LSVG.png" style="width:100%">
						</figure>
						<p>Looks complicated, right? Let's go through it step by step. To keep everything as simple as possible for now, we decided to use the Moving MNIST dataset, a collection of short
						video clips in which two handwritten numbers float around on a black background. First of all, we trained a GAN on individual frames of our dataset to get a generator
						that turns random latent vectors numbers into realistic images of two handwritten digits. As we only need the generator network for our pipeline, we discarded the critic.<br>
						The left half of our pipeline is responsible for conditioning, meaning we use it to define what our generated video will be about.  Therefore, our input consists of an arbitrary number of images containing
						the same two digits at different locations. Eventually, we want to connect those input frames by a generated video. <br>
						We learned that we can generate new images from latent vectors, so now we face the inverse problem: How do we transform our input images into latent vectors
						that we can later use for our video generation?<br>
						Naively, we could just try out a lot of different random vectors, send them through our generator and check whether the images are similar to what our input looks like. Once we find it,
						we would know that this specific random vector must be the latent representation of our image. Obviously, with a latent space of 256 dimensions, that would take forever, so we make use of numerical
						optimization. The L-BFGS optimizer minimizes the difference between our input image and the image generated by a latent vector by continuously adapting the entries in the latent vector, starting from an initial guess.
						To do that, it needs a first derivative. Luckily, our generator is a fully differentiable neural network, so we can use the network's backward pass to calculate our derivative for the L-BFGS optimizer.<br>
						In many cases, this numerical optimization finds a pretty good match in latent space for our input image. Unfortunately, numerical optimization is heavily dependant on initialization, so sometimes it just returns
						absolute rubbish. What do we usually do when well-established methods fail? You're right, we just throw some more deep learning at the problem and hope for the best! In this case, we trained P-NET, which stands for projection
						network. The fully connected neural network's job is to predict the most probable latent vector given an input image. To calculate the network's loss during training, we turn the predicted latent vector into an image using the generator
							and calculate the image similarity of that image to the initial input. </p>
						<figure>
							<img src="images/LSVG/PNET.png" style="width:50%">
						</figure>
						<p>We tried out different combinations of P-NET and numerical optimizers and concluded that we get the best back-projections of input images into latent space by initializing an L-BFGS solver with the output of
						P-NET, which in turn gets our conditioning image as input.</p>
						<p>Now that we've got our input images mapped into our latent space nicely, we need to make a video out of them. We learned about interpolation earlier, but now that we've possibly got more than two points to draw a line between,
						we use regression instead of interpolation.</p>
						<figure>
							<img src="images/LSVG/Regression.svg" style="width:50%">
						</figure>
						<p>As you can see above, the idea is very similar, the is simply calculated as a "best approximation" of all points instead of intersecting with the points directly. We also experimented with using higher-order polynomials instead of lines,
						but the results turned out best with a simple first-order line. This 256-dimensional line through latent space is the first glance at our generated video (it's still a video in latent space, so not very readably for humans...). <br>
						To generate our actual video frames from the line, we have to discretize. Similar to the interpolation problem of images, we simply sample a lot of points from our line. All of those points will later produce one frame of our video.
						</p>
						<p>One problem of latent spaces is the fact that you don't know how many dimensions you need before trying it out. You want to have enough dimensions to capture all your image features,
						but too high-dimensional latent space leads to an unstable regression problem because all of the dimensions are noisy by nature. We discovered that Principal Component Analysis (PCA) alleviates that problem. Let's have a quick look at what PCA is:
						</p>
						<figure>
							<img src="images/LSVG/PCA.png" style="width:50%">
							<figcaption>Image taken from <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">here</a></figcaption>
						</figure>
						<p>As you can see, you need two coordinates to specify the location of the points above. If you place your coordinate system as drawn in black, though, your new x coordinate specifies your point location pretty well! This means by finding the right coordinate
						system, you can reduce the dimensionality of your data to only the important, "principal" dimensions and discard all the excess noise. People usually choose their new axes in a way that retains 95 or 99% of your initial variance in data. <br>
						We found that applying PCA to our latent vectors, then regressing a line in principal space, sampling from this lower-dimensional line and transforming the sampled points back into our initial space improves the resulting videos a lot if the latent space is very
						high-dimensional. You can think of this as only changing the most important aspects in a video from one frame to another. You want your numbers to move, so there will be a lot of variance in the dimensions that correspond to the position,
						but the exact appearance of the digits only changes due to noise, so those changes should be and are filtered out by regressing in PCA.</p>
						<p>At this point, all we have to do to transform our latent video into an actual video is to feed all those sampled latent vectors through our pre-trained generator network to obtain individual video frames.
						If we concatenate the frames into a video clip, we already see numbers floating around, which means out pipeline seems to work! We did, however, notice that the digits do still change their appearance quite vividly.
						This is because the whole process is quite prone to noise, especially if the generator network is not trained to perfection (which is always the case in deep learning), small noise in the latent vectors can lead to very visible
						changes in the resulting video frames. We came up with one last optimization technique to improve our generated videos: critic-correction. <br>
						Remember when I told you we can discard our critic from our GAN training because we only need the generator? Well, at this point, we realized that the critic is very useful to have around, after all, so we went back to the trash can of our cloud and brought it back to life.
						The critic has to assess how real an image looks, so we decided to make use of its ability to do so. We take the frames that our generator produces and pass them through the critic to assess their "realness". We then perform a few steps of gradient ascent,
						meaning we optimize the image to obtain a higher critic score. This changes the images to look more like two actual digits, meaning any strange artifacts and blurriness are removed. By choosing a small step size, we tried to ensure that the numbers aren't changed by the optimization.
						This optimization rests on the assumption that a clearly-written digit is closer to it's blurry and messed-up version than an entirely different digit. While there is no theoretical proof for this assumption, the results seem to confirm that it is sensible. </p>
						<p>Finally, these are short videos that our pipeline generates if you supply 3 singe input images containing the same digits:</p>
						<div class="flex-container">
						<div class="flex-item"><img class="animated-gif" src="images/LSVG/1.gif"> </div>
						<div class="flex-item"><img class="animated-gif" src="images/LSVG/444.gif"> </div>
						<div class="flex-item"><img class="animated-gif" src="images/LSVG/460.gif"> </div>
						<div class="flex-item"><img class="animated-gif" src="images/LSVG/850.gif"> </div>
						</div>
						<p>Pretty cool, right? You can see that the digits are smoothly moving through the frame. As you probably noticed, we still experience a bit of instability in the appearance of the digits
						and sometimes the number even changes, but all in all, we feel like it's a very good start. The main factor for improving the results is achieving a smoother latent space in the initial GAN training. <br>
						We are confident that existing trained GANs can utilize the pipeline we developed to generate high-quality videos and hope to see some results with more exciting content than moving numbers soon!</p>
						<p>This turned out to be a pretty long blog post, but I hope you got the gist of our project and learned a lot on the way. If you have any questions, drop me a message! For technical details of our implementation, check out my <a href="https://github.com/CariusLars/ImprovingVideoGeneration">GitHub Repo</a>. Thanks for reading!</p>

				<!--<h2>Large Heading</h2>

                <p>Harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus <a href="http://#">omnis voluptas assumenda est</a> id quod maxime placeat facere possimus, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et.</p>

                <blockquote><p>This is a simple example of a styled blockquote. A blockquote tag typically specifies a section that is quoted from another source of some sort, or highlighting text in your post.</p></blockquote>

                <p>Odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa. Aenean eu leo quam. Pellentesque ornare sem lacinia quam venenatis vestibulum. Nulla vitae elit libero, a pharetra augue laboris in sit minim cupidatat ut dolor voluptate enim veniam consequat occaecat fugiat in adipisicing in amet Ut nulla nisi non ut enim aliqua laborum mollit quis nostrud sed sed..</p>

                <h3>Smaller Heading</h3>

                <p>Quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus.</p>

                <p>Quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus.</p>

<pre><code>
code {
font-size: 1.4rem;
margin: 0 .2rem;
padding: .2rem .6rem;
white-space: nowrap;
background: #F1F1F1;
border: 1px solid #E1E1E1;
border-radius: 3px;
}
</code></pre>

                <p>Odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa.</p>

                <ul>
                    <li>Donec nulla non metus auctor fringilla.
                        <ul>
                            <li>Lorem ipsum dolor sit amet.</li>
                            <li>Lorem ipsum dolor sit amet.</li>
                            <li>Lorem ipsum dolor sit amet.</li>
                        </ul>
                    </li>
                    <li>Donec nulla non metus auctor fringilla.</li>
                    <li>Donec nulla non metus auctor fringilla.</li>
                </ul>

                <p>Odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa. Aenean eu leo quam. Pellentesque ornare sem lacinia quam venenatis vestibulum. Nulla vitae elit libero, a pharetra augue laboris in sit minim cupidatat ut dolor voluptate enim veniam consequat occaecat fugiat in adipisicing in amet Ut nulla nisi non ut enim aliqua laborum mollit quis nostrud sed sed..</p>
-->
						<!--<p class="tags">
		  			     	<span>Tagged in :</span>
		  				  	<a href="#">orci</a><a href="#">lectus</a><a href="#">varius</a><a href="#">turpis</a>
		  			   </p>-->

		  			   <div class="author-profile">
		  			   	<img src="images/avatars/lars_speaker.jpg" alt="">

		  			   	<div class="about">
		  			   		<h4><a href="#">Lars Carius</a></h4>
		  			   	
		  			   		<p>Master student of "Robotics, Cognition, Intelligence" at TU Munich. Entrepreneur with passion for computer vision, augmented reality, machine learning and simulation.
		  			   		</p>

		  			   		<ul class="author-social">
		  			   			<li><a href="http://www.linkedin.com/in/lars-carius">LinkedIn</a></li>
		  			   		</ul>
		  			   	</div>

					</div> <!-- end entry-primary -->		  			   

	  			   <!--<div class="pagenav group">
		  			   <div class="prev-nav">
		  			   	<a href="#" rel="prev">
		  			   		<span>Previous</span>
		  			   		Tips on Minimalist Design
		  			   	</a>
		  			   </div>
		  				<div class="next-nav">
		  					<a href="#" rel="next">
		  						<span>Next</span>
		  			   		Less Is More
		  					</a>
		  				</div>
	  				</div>-->

				</article>
   		

			</div> <!-- end col-twelve -->
   	</div> <!-- end row -->


   </section> <!-- end content -->


   <!-- footer
   ================================================== -->
   <footer>

   	<div class="footer-main">

   		<div class="row">  

	      	<div class="col-four tab-full mob-full footer-info">            

	            <h4>About This Site</h4>

	               <p>
		          	Welcome to my personal website. You'll find projects from various fields that I conducted at Uni, during hackathons or in my spare time. Have a read through my blogposts and feel free to contact me if you have any questions or are interested in further information and source code.
		          	</p>

		      </div> <!-- end footer-info -->

	      	<div class="col-two tab-1-3 mob-1-2 site-links">

	      		<h4>Site Links</h4>

	      		<ul>
					<li><a href="index.html">Home</a></li>
					<li><a href="about.html">About Me</a></li>
					<li><a href="contact.html">Contact</a></li>
					<li><a href="privacy_policy.html">Privacy Policy</a></li>
				</ul>

	      	</div> <!-- end site-links -->  

	      	<div class="col-two tab-1-3 mob-1-2 social-links">

				<h4>Social</h4>

				<ul><li><a href="http://www.linkedin.com/in/lars-carius">LinkedIn</a></li></ul>
				<ul><li><a href="https://github.com/CariusLars">GitHub</a></li></ul>
				<ul><li><a href="https://www.researchgate.net/profile/Lars_Carius">ResearchGate</a></li></ul>

			</div> <!-- end social links -->

	      	<!--<div class="col-four tab-1-3 mob-full footer-subscribe">

	      		<h4>Subscribe</h4>

	      		<p>Keep yourself updated. Subscribe to our newsletter.</p>

	      		<div class="subscribe-form">

	      			<form id="mc-form" class="group" novalidate="true">

							<input type="email" value="" name="dEmail" class="email" id="mc-email" placeholder="Type &amp; press enter" required="">

			   			<input type="submit" name="subscribe" >

		   				<label for="mc-email" class="subscribe-message"></label>

						</form>

	      		</div>

	      	</div>--> <!-- end subscribe -->

	      </div> <!-- end row -->

   	</div> <!-- end footer-main -->

      <div class="footer-bottom">
      	<div class="row">

      		<div class="col-twelve">
	      		<div class="copyright">
		         	<span>© Copyright Lars Carius 2020</span>
		         	<span>Design by <a href="http://www.styleshout.com/">styleshout</a></span>		         	
		         </div>

		         <div id="go-top">
		            <a class="smoothscroll" title="Back to Top" href="#top"><i class="icon icon-arrow-up"></i></a>
		         </div>         
	      	</div>

      	</div> 
      </div> <!-- end footer-bottom -->  

   </footer>  

   <div id="preloader"> 
    	<div id="loader"></div>
   </div> 

   <!-- Java Script
   ================================================== --> 
   <script src="js/jquery-2.1.3.min.js"></script>
   <script src="js/plugins.js"></script>
   <script src="js/main.js"></script>

</body>

</html>